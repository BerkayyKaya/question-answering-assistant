SelfQueryRetriever'i flan t5 large ile kullanmayı deneyeceksin. (t5-large modeli SelfQuryRetriever'in promptunu anlayabilecek kadar gelişmiş değil)

google/flan-t5-large modelini kullanarak kendi kendime bir SelfQueryRetriever yapmayı denedim. Sonuçlar Türkçe prompt ve metin verdiğimde
hiç iç açıcı değildi ancak İngilizce prompt ve İngilizce metin verdiğimde kısmen doğru sonuçlar alabildim.
İstediğim format {"time": "value", "room": "value", "query": "value"} olmasına rağmen örneğin {"time": "value", "room": "value", "value"}
şeklinde verdi yani query keyini yazmıyordu bunu çözersem hem NER modeli olarak kullanabilirim hem de cevap yazıcı decoder olarak kullanabilirim
 


- mistralai/Mistral-7B-Instruct-v0.2 modelinin 4 bitini bnb config kullanarak yükledim bu sayede 15 GB VRAM gerekirken 6.9 GB VRAM'a aynı işlemi yapabilir duruma geldim.
- Bulutta deploy etmek istiyorsam hem embedding modelinin hem de mistralai/Mistral-7B-Instruct-v0.2 modelinin maliyetlerini araştırmam gerekiyor.
- 7 GB RAM'de gidiyor en az.
- RAM kullanımı kod eklendikçe doğal olarak artıyor.
- LLM kullanarak alan çıkarımı işini hallettim belirli bir tarih veriliyorsa onu kullanıyor verilmiyorsa bahsedilmedi diyor.


- microsoft/Phi-3-mini-4k-instruct modelinin 4 bitini bnb config kullanarak yükledim bu sayede model 4 gb vram'a sahip ekran kartında çalışır hale gelmeye başladı.
- Bulutta deploy etmek istiyorsam hem embedding hem de microsoft/Phi-3-mini-4k-instruct modelinin maliyetlerini araştırmam gerekiyor.
- 



Eğer kendi SelfQueryRetrieverimi yapamazsam,
En kötü ihtimal ya bütün veri seti İngilizceye çevirilecek ya da bert tabanlı Türkçe (İngilizce olması daha mantıklı olabilir) bir model extraction için fine tune edilecek
fine tune edilme işlemi için de ayrı bir veri setine ihtiyacım var.


LLM İÇİN

15 ağustos tarihinde en sıcak oda hangisiydi sorusu patlıyor

en yüksek sıcaklık hangi tarih ve saatte hangi odada olmuş sorusu patlıyor

Oturma odası için en sıcak gün hangi gündü sorusu patlıyor

